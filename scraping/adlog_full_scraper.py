"""
ADLOG ì „ì²´ ë°ì´í„° ìˆ˜ì§‘ ì‹œìŠ¤í…œ
500ê°œ ì‹ë‹¹ ì •ë³´ ë° ìˆœìœ„ ë°ì´í„° ìˆ˜ì§‘
"""

import os
import sys
import time
import json
from datetime import datetime
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup
import pandas as pd
from dotenv import load_dotenv
from supabase import create_client

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
env_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), '.env')
if os.path.exists(env_path):
    load_dotenv(env_path)
    print(f"âœ… .env íŒŒì¼ ë¡œë“œ ì™„ë£Œ")

class AdlogFullScraper:
    def __init__(self, headless=False):
        """ì´ˆê¸°í™”"""
        # ADLOG ë¡œê·¸ì¸ ì •ë³´
        self.username = os.getenv('ADLOG_USERNAME')
        self.password = os.getenv('ADLOG_PASSWORD')
        
        # Supabase ì—°ê²°
        self.supabase_url = os.getenv('SUPABASE_URL')
        self.supabase_key = os.getenv('SUPABASE_ANON_KEY')
        
        if self.supabase_url and self.supabase_key:
            self.supabase = create_client(self.supabase_url, self.supabase_key)
            print("âœ… Supabase ì—°ê²° ì„±ê³µ")
        else:
            self.supabase = None
            print("âš ï¸ Supabase ì—°ê²° ì‹¤íŒ¨ - ë¡œì»¬ ì €ì¥ë§Œ ìˆ˜í–‰")
        
        # Chrome ì˜µì…˜
        self.chrome_options = Options()
        if headless:
            self.chrome_options.add_argument('--headless')
        self.chrome_options.add_argument('--no-sandbox')
        self.chrome_options.add_argument('--disable-dev-shm-usage')
        self.chrome_options.add_argument('--disable-blink-features=AutomationControlled')
        self.chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
        self.chrome_options.add_experimental_option('useAutomationExtension', False)
        self.chrome_options.add_argument('user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36')
        
        self.driver = None
        self.logged_in = False
        
        # ìˆ˜ì§‘ ë°ì´í„°
        self.restaurants = []
        self.rankings = []
        
    def start_driver(self):
        """ë“œë¼ì´ë²„ ì‹œì‘"""
        try:
            print("ğŸš€ Chrome ë“œë¼ì´ë²„ ì‹œì‘...")
            service = Service(ChromeDriverManager().install())
            self.driver = webdriver.Chrome(service=service, options=self.chrome_options)
            self.driver.implicitly_wait(10)
            print("âœ… ë“œë¼ì´ë²„ ì‹œì‘ ì™„ë£Œ")
            return True
        except Exception as e:
            print(f"âŒ ë“œë¼ì´ë²„ ì‹œì‘ ì‹¤íŒ¨: {str(e)}")
            return False
    
    def login(self):
        """ADLOG ë¡œê·¸ì¸"""
        if not self.driver:
            if not self.start_driver():
                return False
        
        try:
            print("\nğŸ” ADLOG ë¡œê·¸ì¸ ì¤‘...")
            
            # 1. ë©”ì¸ í˜ì´ì§€ ì ‘ì†
            self.driver.get("https://adlog.kr")
            time.sleep(2)
            
            # 2. ë¡œê·¸ì¸ í˜ì´ì§€ë¡œ ì´ë™
            try:
                login_link = self.driver.find_element(By.LINK_TEXT, "ë¡œê·¸ì¸")
                login_link.click()
            except:
                self.driver.get("https://adlog.kr/login")
            
            time.sleep(2)
            
            # 3. ë¡œê·¸ì¸ ì •ë³´ ì…ë ¥
            # ID ì…ë ¥
            id_input = None
            for name in ['userid', 'id', 'username']:
                try:
                    id_input = self.driver.find_element(By.NAME, name)
                    break
                except:
                    continue
            
            if not id_input:
                id_input = self.driver.find_element(By.CSS_SELECTOR, "input[type='text']")
            
            id_input.clear()
            id_input.send_keys(self.username)
            
            # PW ì…ë ¥
            pw_input = None
            for name in ['passwd', 'password', 'pw']:
                try:
                    pw_input = self.driver.find_element(By.NAME, name)
                    break
                except:
                    continue
            
            if not pw_input:
                pw_input = self.driver.find_element(By.CSS_SELECTOR, "input[type='password']")
            
            pw_input.clear()
            pw_input.send_keys(self.password)
            pw_input.send_keys(Keys.RETURN)
            
            time.sleep(3)
            
            # 4. ë¡œê·¸ì¸ ì„±ê³µ í™•ì¸
            if "login" not in self.driver.current_url.lower():
                self.logged_in = True
                print("âœ… ë¡œê·¸ì¸ ì„±ê³µ!")
                return True
            else:
                print("âŒ ë¡œê·¸ì¸ ì‹¤íŒ¨")
                return False
                
        except Exception as e:
            print(f"âŒ ë¡œê·¸ì¸ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return False
    
    def get_restaurant_list(self):
        """500ê°œ ì‹ë‹¹ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° (í˜ì´ì§€ë„¤ì´ì…˜ ì²˜ë¦¬)"""
        if not self.logged_in:
            if not self.login():
                return []
        
        try:
            print("\nğŸ“Š ì‹ë‹¹ ëª©ë¡ ìˆ˜ì§‘ ì¤‘ (500ê°œ ëª©í‘œ)...")
            
            # ìˆœìœ„ ì²´í¬ í˜ì´ì§€ë¡œ ì´ë™
            self.driver.get("https://adlog.kr/adlog/naver_place_rank_check.php")
            time.sleep(3)
            
            restaurants = []
            page_num = 1
            max_pages = 10  # ìµœëŒ€ 10í˜ì´ì§€ê¹Œì§€ í™•ì¸
            
            while page_num <= max_pages:
                print(f"\nğŸ“„ {page_num}í˜ì´ì§€ ìˆ˜ì§‘ ì¤‘...")
                
                # í˜„ì¬ í˜ì´ì§€ íŒŒì‹±
                soup = BeautifulSoup(self.driver.page_source, 'html.parser')
                
                # í…Œì´ë¸”ì—ì„œ ì‹ë‹¹ ì •ë³´ ì¶”ì¶œ
                tables = soup.find_all('table')
                page_restaurants = 0
                
                for table in tables:
                    rows = table.find_all('tr')[1:]  # í—¤ë” ì œì™¸
                    for row in rows:
                        cols = row.find_all('td')
                        if len(cols) >= 2:
                            # place URL ì¶”ì¶œ
                            place_link = row.find('a', href=lambda x: x and 'place.naver.com' in x)
                            if place_link:
                                place_url = place_link.get('href')
                                # place_id ì¶”ì¶œ
                                if '/restaurant/' in place_url:
                                    place_id = place_url.split('/restaurant/')[-1].split('?')[0]
                                else:
                                    place_id = place_url.split('/')[-1].split('?')[0]
                                
                                # ì¤‘ë³µ ì²´í¬
                                if not any(r['place_id'] == place_id for r in restaurants):
                                # ë¸”ë¡œê·¸ ìˆ˜ì™€ ë°©ë¬¸ìë¦¬ë·° ìˆ˜ ì¶”ì¶œ
                                blog_count = 0
                                visitor_count = 0
                                n1_score = 0.0
                                n2_score = 0.0
                                n3_score = 0.0
                                
                                # í…Œì´ë¸” ì»´ëŸ¼ì—ì„œ ë°ì´í„° ì°¾ê¸°
                                for idx, col in enumerate(cols):
                                    col_text = col.get_text(strip=True)
                                    
                                    # ë¸”ë¡œê·¸/ë°©ë¬¸ì ìˆ˜ (ìˆ«ì,ìˆ«ì í˜•íƒœ)
                                    if ',' in col_text and col_text.replace(',', '').isdigit():
                                        try:
                                            num = int(col_text.replace(',', ''))
                                            if blog_count == 0:
                                                blog_count = num
                                            elif visitor_count == 0:
                                                visitor_count = num
                                        except:
                                            pass
                                    
                                    # N1, N2, N3 ì ìˆ˜ (0.XXXXXX í˜•íƒœ)
                                    elif '0.' in col_text:
                                        try:
                                            score = float(col_text)
                                            if 0.56 <= score <= 0.58 and n1_score == 0:  # N1 ë²”ìœ„
                                                n1_score = score
                                            elif 0.79 <= score <= 0.83 and n2_score == 0:  # N2 ë²”ìœ„
                                                n2_score = score
                                            elif 0.43 <= score <= 0.44 and n3_score == 0:  # N3 ë²”ìœ„
                                                n3_score = score
                                        except:
                                            pass
                                
                                restaurant = {
                                    'place_id': place_id,
                                    'place_name': cols[1].get_text(strip=True),
                                    'place_url': f"https://m.place.naver.com/restaurant/{place_id}",
                                    'category': cols[2].get_text(strip=True) if len(cols) > 2 else '',
                                    'address': cols[3].get_text(strip=True) if len(cols) > 3 else '',
                                    'blog_count': blog_count,
                                    'visitor_review_count': visitor_count,
                                    'n1_score': n1_score if n1_score > 0 else None,
                                    'n2_score': n2_score if n2_score > 0 else None,
                                    'n3_score': n3_score if n3_score > 0 else None,
                                    'collected_at': datetime.now().isoformat()
                                }
                                    restaurants.append(restaurant)
                                    page_restaurants += 1
                                    print(f"  ğŸ“ {len(restaurants)}. {restaurant['place_name']} (ID: {place_id})")
                
                print(f"  âœ… {page_num}í˜ì´ì§€: {page_restaurants}ê°œ ì‹ë‹¹ ìˆ˜ì§‘")
                
                # 500ê°œ ë„ë‹¬ ì‹œ ì¤‘ë‹¨
                if len(restaurants) >= 500:
                    print(f"\nğŸ¯ ëª©í‘œ 500ê°œ ë‹¬ì„±! (í˜„ì¬: {len(restaurants)}ê°œ)")
                    break
                
                # ë‹¤ìŒ í˜ì´ì§€ë¡œ ì´ë™
                try:
                    # í˜ì´ì§€ ë²ˆí˜¸ í´ë¦­ ì‹œë„
                    next_page = None
                    
                    # ë°©ë²• 1: ìˆ«ì ë²„íŠ¼ ì°¾ê¸°
                    page_links = self.driver.find_elements(By.CSS_SELECTOR, "a.page-link, button.page-link")
                    for link in page_links:
                        if link.text.strip() == str(page_num + 1):
                            next_page = link
                            break
                    
                    # ë°©ë²• 2: "ë‹¤ìŒ" ë˜ëŠ” "ë”ë³´ê¸°" ë²„íŠ¼
                    if not next_page:
                        for text in ['ë‹¤ìŒ', 'ë”ë³´ê¸°', 'Next', '>', '>>', 'ë‹¤ìŒ í˜ì´ì§€']:
                            try:
                                next_page = self.driver.find_element(By.LINK_TEXT, text)
                                break
                            except:
                                try:
                                    next_page = self.driver.find_element(By.PARTIAL_LINK_TEXT, text)
                                    break
                                except:
                                    continue
                    
                    # ë°©ë²• 3: í˜ì´ì§€ë„¤ì´ì…˜ ì˜ì—­ì—ì„œ ì°¾ê¸°
                    if not next_page:
                        pagination = self.driver.find_element(By.CSS_SELECTOR, ".pagination, .paging, .page-navigation")
                        links = pagination.find_elements(By.TAG_NAME, "a")
                        for link in links:
                            if str(page_num + 1) in link.text:
                                next_page = link
                                break
                    
                    if next_page:
                        self.driver.execute_script("arguments[0].scrollIntoView(true);", next_page)
                        time.sleep(1)
                        next_page.click()
                        time.sleep(3)
                        page_num += 1
                    else:
                        print(f"\nâš ï¸ ë” ì´ìƒ í˜ì´ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. (ë§ˆì§€ë§‰ í˜ì´ì§€: {page_num})")
                        break
                        
                except Exception as e:
                    print(f"\nâš ï¸ í˜ì´ì§€ ì´ë™ ì‹¤íŒ¨: {str(e)}")
                    # ë”ë³´ê¸° ë²„íŠ¼ ì‹œë„
                    try:
                        more_btn = self.driver.find_element(By.CSS_SELECTOR, "button:contains('ë”ë³´ê¸°'), a:contains('ë”ë³´ê¸°')")
                        more_btn.click()
                        time.sleep(3)
                        page_num += 1
                    except:
                        print("ë” ì´ìƒ í˜ì´ì§€ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        break
            
            # ì¶”ê°€ ë°©ë²•: Select ë°•ìŠ¤ë‚˜ ë“œë¡­ë‹¤ìš´ì—ì„œ ì‹ë‹¹ ëª©ë¡ ì¶”ì¶œ
            if len(restaurants) < 500:
                try:
                    # select ë°•ìŠ¤ ì°¾ê¸°
                    select_elements = self.driver.find_elements(By.TAG_NAME, "select")
                    for select in select_elements:
                        options = select.find_elements(By.TAG_NAME, "option")
                        for option in options:
                            value = option.get_attribute('value')
                            if value and 'place.naver.com' in value:
                                if '/restaurant/' in value:
                                    place_id = value.split('/restaurant/')[-1].split('?')[0]
                                    if not any(r['place_id'] == place_id for r in restaurants):
                                        restaurants.append({
                                            'place_id': place_id,
                                            'place_name': option.text.strip(),
                                            'place_url': f"https://m.place.naver.com/restaurant/{place_id}",
                                            'collected_at': datetime.now().isoformat()
                                        })
                                        print(f"  ğŸ“ {len(restaurants)}. {option.text.strip()} (ID: {place_id})")
                except:
                    pass
            
            self.restaurants = restaurants
            print(f"âœ… ì´ {len(restaurants)}ê°œ ì‹ë‹¹ ë°œê²¬")
            
            # ë¡œì»¬ ì €ì¥
            self.save_to_json(restaurants, "restaurants_list.json")
            
            return restaurants
            
        except Exception as e:
            print(f"âŒ ì‹ë‹¹ ëª©ë¡ ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}")
            return []
    
    def search_keyword_ranking(self, keyword):
        """íŠ¹ì • í‚¤ì›Œë“œë¡œ ìˆœìœ„ ê²€ìƒ‰"""
        if not self.logged_in:
            if not self.login():
                return []
        
        try:
            print(f"\nğŸ” '{keyword}' ê²€ìƒ‰ ì¤‘...")
            
            # ìˆœìœ„ ì²´í¬ í˜ì´ì§€ë¡œ ì´ë™
            self.driver.get("https://adlog.kr/adlog/naver_place_rank_check.php")
            time.sleep(2)
            
            # ê²€ìƒ‰ì–´ ì…ë ¥
            search_input = None
            
            # ì—¬ëŸ¬ ë°©ë²•ìœ¼ë¡œ ê²€ìƒ‰ ì…ë ¥ í•„ë“œ ì°¾ê¸°
            for selector in [
                "input[name='keyword']",
                "input[name='search']",
                "input[name='query']",
                "input[type='text']"
            ]:
                try:
                    search_input = self.driver.find_element(By.CSS_SELECTOR, selector)
                    if search_input.is_displayed():
                        break
                except:
                    continue
            
            if search_input:
                search_input.clear()
                search_input.send_keys(keyword)
                
                # ê²€ìƒ‰ ì‹¤í–‰
                try:
                    # Enter í‚¤ë¡œ ê²€ìƒ‰
                    search_input.send_keys(Keys.RETURN)
                except:
                    # ë²„íŠ¼ í´ë¦­
                    submit_btn = self.driver.find_element(By.CSS_SELECTOR, "input[type='submit']")
                    submit_btn.click()
                
                time.sleep(3)
                
                # ê²°ê³¼ íŒŒì‹±
                soup = BeautifulSoup(self.driver.page_source, 'html.parser')
                
                rankings = []
                rank = 1
                
                # ìˆœìœ„ í…Œì´ë¸” íŒŒì‹±
                result_table = soup.find('table', class_='ranking') or soup.find('table')
                if result_table:
                    rows = result_table.find_all('tr')[1:]
                    for row in rows[:20]:  # ìƒìœ„ 20ê°œë§Œ
                        cols = row.find_all('td')
                        if len(cols) >= 2:
                            place_name = cols[1].get_text(strip=True)
                            
                            # place_id ì°¾ê¸°
                            place_link = row.find('a', href=lambda x: x and 'place.naver.com' in x)
                            place_id = None
                            if place_link:
                                href = place_link.get('href')
                                if '/restaurant/' in href:
                                    place_id = href.split('/restaurant/')[-1].split('?')[0]
                            
                            # ë¸”ë¡œê·¸ ìˆ˜ì™€ ë°©ë¬¸ìë¦¬ë·° ìˆ˜ ì¶”ì¶œ
                            blog_count = 0
                            visitor_count = 0
                            
                            # ì»´ëŸ¼ì—ì„œ ìˆ«ì ë°ì´í„° ì°¾ê¸°
                            for idx, col in enumerate(cols):
                                if idx > 2:  # ìˆœìœ„, ì´ë¦„ ì´í›„ ì»´ëŸ¼
                                    col_text = col.get_text(strip=True)
                                    if ',' in col_text:
                                        try:
                                            num = int(col_text.replace(',', ''))
                                            if blog_count == 0:
                                                blog_count = num
                                            elif visitor_count == 0:
                                                visitor_count = num
                                        except:
                                            pass
                            
                            ranking_data = {
                                'search_keyword': keyword,
                                'rank': rank,
                                'place_name': place_name,
                                'place_id': place_id,
                                'blog_count': blog_count,
                                'visitor_review_count': visitor_count,
                                'search_date': datetime.now().strftime('%Y-%m-%d'),
                                'search_time': datetime.now().strftime('%H:%M:%S')
                            }
                            rankings.append(ranking_data)
                            print(f"    {rank}ìœ„: {place_name}")
                            rank += 1
                
                return rankings
            else:
                print("âŒ ê²€ìƒ‰ ì…ë ¥ í•„ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                return []
                
        except Exception as e:
            print(f"âŒ í‚¤ì›Œë“œ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
            return []
    
    def collect_all_rankings(self):
        """ëª¨ë“  í‚¤ì›Œë“œë¡œ ìˆœìœ„ ìˆ˜ì§‘"""
        # Supabaseì—ì„œ í‚¤ì›Œë“œ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        keywords = []
        
        if self.supabase:
            try:
                result = self.supabase.table('tracking_keywords').select("keyword").eq('is_active', True).execute()
                keywords = [item['keyword'] for item in result.data]
                print(f"ğŸ“‹ {len(keywords)}ê°œ í‚¤ì›Œë“œ ë¡œë“œ")
            except:
                pass
        
        # ê¸°ë³¸ í‚¤ì›Œë“œ
        if not keywords:
            keywords = [
                "ê°•ë‚¨ ë§›ì§‘", "ê°•ë‚¨ ì¹˜í‚¨", "ê°•ë‚¨ ì¹´í˜",
                "í•´ìš´ëŒ€ ë§›ì§‘", "í•´ìš´ëŒ€ ê³ ê¸°ì§‘",
                "ì„œì´ˆ ë§›ì§‘", "ì†¡íŒŒ ë§›ì§‘"
            ]
        
        all_rankings = []
        
        for keyword in keywords:
            rankings = self.search_keyword_ranking(keyword)
            all_rankings.extend(rankings)
            time.sleep(3)  # API ë¶€í•˜ ë°©ì§€
        
        self.rankings = all_rankings
        print(f"\nâœ… ì´ {len(all_rankings)}ê°œ ìˆœìœ„ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")
        
        # ë¡œì»¬ ì €ì¥
        self.save_to_json(all_rankings, "rankings_data.json")
        
        return all_rankings
    
    def save_to_database(self):
        """Supabaseì— ë°ì´í„° ì €ì¥"""
        if not self.supabase:
            print("âš ï¸ Supabase ì—°ê²° ì—†ìŒ - ë¡œì»¬ ì €ì¥ë§Œ ì™„ë£Œ")
            return
        
        try:
            print("\nğŸ’¾ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì¤‘...")
            
            # 1. ì‹ë‹¹ ì •ë³´ ì €ì¥
            if self.restaurants:
                for restaurant in self.restaurants:
                    self.supabase.table('adlog_restaurants').upsert({
                        'place_id': restaurant['place_id'],
                        'place_name': restaurant.get('place_name', ''),
                        'category': restaurant.get('category', ''),
                        'address': restaurant.get('address', ''),
                        'place_url': restaurant.get('place_url', ''),
                        'is_active': True,
                        'updated_at': datetime.now().isoformat()
                    }).execute()
                print(f"  âœ… {len(self.restaurants)}ê°œ ì‹ë‹¹ ì €ì¥")
            
            # 2. ìˆœìœ„ ë°ì´í„° ì €ì¥
            if self.rankings:
                today = datetime.now().strftime('%Y-%m-%d')
                current_time = datetime.now().strftime('%H:%M:%S')
                
                for ranking in self.rankings:
                    # ì‹ë‹¹ ID ì¡°íšŒ
                    if ranking.get('place_id'):
                        restaurant = self.supabase.table('adlog_restaurants')\
                            .select("id")\
                            .eq('place_id', ranking['place_id'])\
                            .execute()
                        
                        if restaurant.data:
                            restaurant_id = restaurant.data[0]['id']
                            
                            self.supabase.table('daily_rankings').upsert({
                                'search_date': today,
                                'search_time': current_time,
                                'search_keyword': ranking['search_keyword'],
                                'restaurant_id': restaurant_id,
                                'rank': ranking['rank'],
                                'blog_count': ranking.get('blog_count', 0),
                                'visitor_review_count': ranking.get('visitor_review_count', 0),
                                'reservation_count': ranking.get('reservation_count', 0),
                                'n1_score': ranking.get('n1_score'),
                                'n2_score': ranking.get('n2_score'),
                                'n3_score': ranking.get('n3_score')
                            }).execute()
                
                print(f"  âœ… {len(self.rankings)}ê°œ ìˆœìœ„ ì €ì¥")
            
            print("âœ… ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì™„ë£Œ!")
            
        except Exception as e:
            print(f"âŒ DB ì €ì¥ ì‹¤íŒ¨: {str(e)}")
    
    def save_to_json(self, data, filename):
        """JSON íŒŒì¼ë¡œ ì €ì¥"""
        filepath = f"data/{filename}"
        os.makedirs(os.path.dirname(filepath), exist_ok=True)
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        print(f"  ğŸ’¾ ë¡œì»¬ ì €ì¥: {filepath}")
    
    def save_to_csv(self):
        """CSV íŒŒì¼ë¡œ ì €ì¥"""
        if self.restaurants:
            df_restaurants = pd.DataFrame(self.restaurants)
            df_restaurants.to_csv('data/restaurants.csv', index=False, encoding='utf-8-sig')
            print(f"  ğŸ’¾ ì‹ë‹¹ CSV ì €ì¥: data/restaurants.csv")
        
        if self.rankings:
            df_rankings = pd.DataFrame(self.rankings)
            df_rankings.to_csv('data/rankings.csv', index=False, encoding='utf-8-sig')
            print(f"  ğŸ’¾ ìˆœìœ„ CSV ì €ì¥: data/rankings.csv")
    
    def close(self):
        """ë¸Œë¼ìš°ì € ì¢…ë£Œ"""
        if self.driver:
            self.driver.quit()
            print("âœ… ë¸Œë¼ìš°ì € ì¢…ë£Œ")
    
    def run_full_collection(self):
        """ì „ì²´ ìˆ˜ì§‘ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰"""
        print("\n" + "="*60)
        print("ğŸš€ ADLOG ì „ì²´ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
        print("="*60)
        
        # 1. ë¡œê·¸ì¸
        if not self.login():
            print("âŒ ë¡œê·¸ì¸ ì‹¤íŒ¨ë¡œ ì¤‘ë‹¨")
            return
        
        # 2. ì‹ë‹¹ ëª©ë¡ ìˆ˜ì§‘
        self.get_restaurant_list()
        
        # 3. ìˆœìœ„ ë°ì´í„° ìˆ˜ì§‘
        self.collect_all_rankings()
        
        # 4. ë°ì´í„° ì €ì¥
        self.save_to_database()
        self.save_to_csv()
        
        # 5. ìš”ì•½
        print("\n" + "="*60)
        print("ğŸ“Š ìˆ˜ì§‘ ì™„ë£Œ ìš”ì•½")
        print("="*60)
        print(f"  â€¢ ì‹ë‹¹: {len(self.restaurants)}ê°œ")
        print(f"  â€¢ ìˆœìœ„ ë°ì´í„°: {len(self.rankings)}ê°œ")
        print(f"  â€¢ ìˆ˜ì§‘ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("="*60)


# ì‹¤í–‰
if __name__ == "__main__":
    scraper = AdlogFullScraper(headless=False)  # í…ŒìŠ¤íŠ¸ ì‹œ í™”ë©´ ë³´ê¸°
    
    try:
        scraper.run_full_collection()
    finally:
        scraper.close()
